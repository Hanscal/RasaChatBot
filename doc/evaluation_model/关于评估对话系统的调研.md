# 关于评估对话系统的调研

rasa 对话系统的评估模型，官网网址：https://rasa.com/docs/rasa/testing-your-assistant/

对话系统rasa - 评估模型（翻译），网址：https://zhuanlan.zhihu.com/p/88980657



## 测试语音助手

Rasa开源允许您通过运行测试故事来验证和测试端到端的对话。此外，还可以分别测试对话管理和消息处理（NLU）。

### 1. 验证数据和故事

数据验证可验证您的domain、NLU数据或故事数据中是否出现错误或重大不一致。要验证数据，请让CI运行以下命令：

```python
rasa data validate
```

如果将**max_history**值传递给**config.yml**文件中的一个或多个策略，请提供这些值中最小的值，如下所示：

````python 
rasa data validate --max-history <max_history>
````

如果数据验证导致错误，训练模型也可能失败或产生不良性能，因此在训练模型之前运行此检查总是好的。通过包含**--fail-on-warnings**标志，此步骤将在显示更多小问题的警告时失败。

#####  NOTE

> 运行**rasa data validate**不会测试你的规则是否与你的故事一致。然而，在训练期间，**RulePolicy**会检查规则和故事之间的冲突。任何这样的冲突都会导致训练中断。

要阅读有关验证程序和所有可用选项的更多信息，请参阅rasa数据验证的文档。

### 2. 测试故事

在测试故事中测试你训练有素的模型是对你的助手在某些情况下的行为有信心的最佳方式。测试故事以修改后的故事格式编写，允许您提供完整的对话，并测试在给定特定用户输入的情况下，您的模型将以预期的方式运行。当你开始从用户对话中引入更复杂的故事时，这一点尤为重要。

测试故事与训练数据中的故事类似，但也包括用户消息。

默认情况下，该命令将对任何名称以**test_**开头的文件中的故事运行测试。还可以使用**--stories**参数提供特定的测试故事文件或目录。您可以通过运行以下命令来测试助手：

```python
rasa test
```

对话测试只与测试用例一样全面和准确，所以在对助手进行改进的同时，您应该继续增加测试用例集。一个很好的经验法则是，你应该让你的测试故事代表真实对话的真实分布。Rasa X使基于真实对话添加测试对话变得容易。

有关更多配置选项，请参阅rasa测试的CLI文档。

#### 测试自定义操作

> 自定义操作不会作为测试故事的一部分执行。如果您的自定义操作将任何事件附加到对话中，这必须反映在您的测试故事中（例如，通过向您的测试故事中添加slot_was_set事件）。

> 要测试自定义操作的代码，应该为它们编写单元测试，并将这些测试包括在CI/CD pipeline中。

### 3. 评估NLU模型

除了测试故事，还可以单独测试自然语言理解（NLU）模型。一旦你的助手部署到现实世界中，它将处理训练数据中没有看到的消息。为了模拟这种情况，您应该始终留出部分数据进行测试。您可以使用以下方法将NLU数据拆分为训练集和测试集：

```python
rasa data split nlu
```

接下来，您可以使用以下方法查看经过训练的NLU模型对生成的测试集数据的预测效果：

```python
rasa test nlu
    --nlu train_test_split/test_data.yml
```

要更广泛地测试模型，请使用交叉验证，它会自动创建多个训练/测试拆分：

```python
rasa test nlu
    --nlu data/nlu.yml
    --cross-validation
```

#### NLU性能比较

如果您对NLU训练数据进行了重大更改（例如，将一个意图拆分为两个意图或添加了大量训练示例），则应进行完整的NLU评估。您需要比较NLU模型的性能，而不需要对NLU模型进行更改。

可以通过在交叉验证模式下运行NLU测试来实现这一点：

```python
rasa test nlu --cross-validation
```

您还可以在训练集上训练模型，并在测试集上进行测试。如果使用**train-test**集方法，最好使用**rasa data split**（作为CI步骤的一部分）对数据进行洗牌和拆分，而不是使用静态NLU测试集，后者很容易过时。

您可以在rasa测试的CLI文档中找到完整的选项列表。

##### 超参数调谐

要进一步改进模型，请查看此超参数调整教程。

#### 比较 NLU Pipelines

为了最大限度地利用训练数据，您应该在不同的pipeline和不同数量的训练数据上训练和评估您的模型。

为此，请将多个配置文件传递给**rasa test**命令：

```python
rasa test nlu --nlu data/nlu.yml
   --config config_1.yml config_2.yml
```

这将执行几个步骤：

1. 从**data/nlu.yml**创建一个全局80%的训练集/20%的测试拆分。

2. 从全局训练拆分中排除一定百分比的数据。

3. 根据剩余的训练数据，为每个配置提供训练模型。

4. 在全局测试拆分中评估每个模型。

在第2步中，使用不同百分比的训练数据重复上述过程，以了解如果增加训练数据量，每个pipeline将如何运行。由于训练不是完全确定的，所以对于每个指定的配置，整个过程重复三次。

绘制了一张图，显示了所有运行中**f1-scores**的平均值和标准差。**f1-scores**图以及所有训练/测试集、训练模型、分类和错误报告将保存到名为**nlu_comparison_results**的文件夹中。

查看**f1-scores**图可以帮助您了解NLU模型是否有足够的数据。如果图表显示，当使用所有训练数据时，**f1-scores**仍在提高，则更多数据可能会进一步提高。但是，如果在使用所有训练数据时**f1-scores**已经稳定下来，添加更多数据可能没有帮助。

如果要更改运行次数或排除百分比，可以：

```python
rasa test nlu --nlu data/nlu.yml
  --config config_1.yml config_2.yml
  --runs 4 --percentages 0 25 50 70 90
```

#### 解读输出

##### 意图分类器

**rasa test**脚本将为您的意图分类模型生成一个报告（**intent_report.json**）、混淆矩阵（**intent_conflusion_matrix.png**）和置信度直方图（**intent_histogram.png**）。

该报告记录了每个意图的准确度、召回率和**f1-score**，并提供了总体平均值。可以使用**--report**参数将这些报告保存为**JSON**文件。

混淆矩阵显示了哪些意图被误认为其他意图。任何被错误预测的样本都会被记录并保存到名为**errors.json**的文件中，以便于调试。

![intent_confusion_matrix](D:\GitLib\RasaChatBot\results\intent_confusion_matrix.png)

直方图允许您可视化所有预测的置信度，正确预测和错误预测分别以蓝色和红色条显示。提高训练数据的质量将使蓝色柱状图向上移动，红色柱状图向下移动。它还应有助于减少红色直方图条本身的数量。

![intent_histogram](D:\GitLib\RasaChatBot\results\intent_histogram.png)

#### 响应选择器

**rasa test**评估响应选择器的方式与评估意图分类器的方式相同，它会生成一个报告（**response_selection_report.json**）、混淆矩阵（**response_selection_conflusion_matrix.png**）、置信度直方图（**response_selection_histogram.png**）和误差（**response_selection_errors.json**）。如果您的**pipeline**包含多个响应选择器，则会在单个报告中对其进行评估。

该报告记录了检索意图的每个子意图的精确度、召回率和**f1**度量，并提供了总体平均值。可以使用**--report**参数将这些报告保存为**JSON**文件。

#### 实体提取

**rasa test**报告可训练实体提取器训练识别的每种实体类型的召回率、精确度和**f1-score**。

只有可训练的实体提取器，如**DIETClassifier**和**CRFEntityExtractor**，才能通过**rasa test**进行评估。未对**DucklingHTTPExtractor**等预训练提取器进行评估。

如果**pipeline**中有多个实体提取器，或者使用一些自定义提取器，则多个实体可能与同一**token**关联。在这种情况下，可以在测试文件中使用列表表示法，例如

``` python
stories:
- story: A basic test story with mutliple entities for a single token
  steps:
    - user: |
        I like [ice cream][{\"entity\": \"food\"}, {\"entity\": \"desert\"}]
      intent: inform
    # ...
```

#### 不正确的实体注释

如果任何实体的注释不正确，评估可能会失败。一个常见的问题是，实体不能在**token**内停止或启动。例如，如果您有一个**name**实体的示例，比如**\[ Brian \](name)'s house**，那么只有当您的**tokenizer**将**Brian's**拆分为多个**tokens**时，这才有效。

#### 实体评分

为了评估实体提取，我们采用了一种简单的基于标记的方法。我们不完全考虑**BILOU**标记，只考虑基于每个标记的实体类型标记。对于**“near Alexanderplatz”**等位置实体，我们希望标签为**LOC LOC**，而不是基于**BILOU**的**B-LOC L-LOC**。

在评估方面，我们的方法更加宽松，因为它奖励部分提取，不惩罚实体的分裂。例如，鉴于上述实体**“near Alexanderplatz”**和提取**“Alexanderplatz”**的系统，我们的方法奖励提取**“Alexanderplatz”**，惩罚漏掉的单词**“near”**。

然而，基于**BILOU**的方法会将其标记为完全失败，因为它期望**Alexanderplatz**被标记为实体**（L-LOC）**中的最后一个**token**，而不是单个**token**实体**（U-LOC）**。还要注意的是，将**“near”**和**“Alexanderplatz”**分开提取，我们的方法会得到满分，而基于**BILOU**的方法会得到零分。

下面是对短语“**near Alexanderplatz tonight**”的两种评分机制的比较：

| extracted                                           | Simple tags (score) | BILOU tags (score)     |
| :-------------------------------------------------- | :------------------ | :--------------------- |
| `[near Alexanderplatz](loc) [tonight](time)`        | loc loc time (3)    | B-loc L-loc U-time (3) |
| `[near](loc) [Alexanderplatz](loc) [tonight](time)` | loc loc time (3)    | U-loc U-loc U-time (1) |
| `near [Alexanderplatz](loc) [tonight](time)`        | O loc time (2)      | O U-loc U-time (1)     |
| `[near](loc) Alexanderplatz [tonight](time)`        | loc O time (2)      | U-loc O U-time (1)     |
| `[near Alexanderplatz tonight](loc)`                | loc loc loc (2)     | B-loc I-loc L-loc (1)  |

### 4. 评估对话模型

您可以使用测试脚本，在一组测试故事中评估经过训练的对话模型：

```
rasa test core --stories test_stories.yml --out results
```

这将把所有失败的故事打印到**results/failed_test_stories.yml**中。如果至少有一个动作被错误预测，故事就会失败。

测试脚本还将把混淆矩阵保存到名为**results/story_confmat.pdf**的文件中。对于域中的每个动作，混淆矩阵显示正确预测动作的频率，以及预测错误动作的频率。

#### 解释生成的警告

测试脚本还将生成一个名为**results/stories_with_warnings.yml**的警告文件。该文件包含在任何对话回合中预测**action_unlikely_intent**的所有测试故事，但原始故事中的所有动作都预测正确。然而，如果一个测试故事最初包含了一个**action_unlikely_intent**，例如，为了确保一个规则被设计为在**action_unlikely_intent**之后触发对话路径，但策略集合没有这样做，那么相应的故事最终将在**results/failed_test_stories.yml**中作为一个失败的故事结束。

这些故事是按照**action_unlikely_intent**预测的严重程度排序的。该严重性由**UnexpecTEDIntentPolicy**在预测时自行计算。严重性越高，意图就越不可能，因此审查特定的对话路径就变得越关键。

请注意，**action_unlikely_intent**是由**UnexpecTEDIntentPolicy**预测的，它在引擎盖下使用了基于机器学习的模型，因此也可能导致错误警告。如果训练故事中已经存在这些故事中的对话路径，则可以选择忽略这些警告。

#### 比较策略配置

要为对话模型选择配置，或为特定策略选择超参数，您需要衡量对话模型对以前从未见过的对话的概括程度。尤其是在项目开始时，当你没有很多真实的对话来训练你的机器人时，你可能不想排除一些对话来用作测试集。

Rasa开源有一些脚本可以帮助您选择和微调策略配置。一旦你对它感到满意，你就可以在你的完整数据集上训练你的最终配置。

要做到这一点，首先必须针对不同的配置训练模型。创建两个（或更多）配置文件，包括要比较的策略，然后将它们提供给训练脚本以训练模型：

```
rasa train core -c config_1.yml config_2.yml \
  --out comparison_models --runs 3 --percentages 0 5 25 50 70 95
```

与NLU模型的评估方式类似，上述命令在多种配置和不同数量的训练数据上训练对话模型。对于提供的每个配置文件，Rasa开源将训练对话模型，其中0、5、25、50、70和95%的训练故事将从训练数据中排除。重复三次，以确保结果一致。

此脚本完成后，您可以将多个模型传递给测试脚本，以比较刚刚训练的模型：

```
rasa test core -m comparison_models --stories stories_folder
  --out comparison_results --evaluate-model-directory
```

这将评估**stories_folder**中故事的每个模型（可以是训练集或测试集），并绘制一些图表，向您展示哪个策略表现最好。由于之前的训练命令排除了训练每个模型所需的一些训练数据，因此上面的测试命令可以测量您的模型预测已完成故事的程度。要比较单个策略，请创建每个策略只包含一个策略的配置文件。

####  NOTE

这个训练过程可能需要很长时间，所以我们建议让它在后台运行，这样就不会被打断。

#### 测试动作代码

用于测试动作代码的方法将取决于它的实现方式。例如，如果连接到外部API，则应该编写集成测试，以确保这些API按照预期响应公共输入。无论如何测试操作代码，都应该在CI pipeline中包含这些测试，以便在每次进行更改时运行这些测试。

